=========================> 建表语法

CREATE   [EXTERNAL]   TABLE   [IF NOT EXISTS]   table_name (
cluster_id  STRING  comment'',
total  STRING  comment'',
dia_date STRING  comment''
) COMMENT 'table_comment'
PARTITIONED BY (col_name data_type COMMENT 'col_comment', ...)
[CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
ROW FORMAT DELIMITED
[FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]

STORED AS file_format
LOCATION hdfs_path ;

说明：
1、	CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。
2、	EXTERNAL关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。
3、	LIKE 允许用户复制现有的表结构，但是不复制数据。
4、	ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
   | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]
用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive通过 SerDe 确定表的具体的列的数据。
5、	STORED AS
SEQUENCEFILE|TEXTFILE|RCFILE
如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。

6、CLUSTERED BY
对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。
把表（或者分区）组织成桶（Bucket）有两个理由：
（1）获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。
（2）使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。

例子: 创建分区表
create table student_p(
Sno int,
Sname string,
Sage int,
Sdept string)
partitioned by(part string)
row format delimited
fields terminated by ','
stored as textfile;


================================================>  load 数据

1. load 本地数据
load data local inpath '/jobcount/data' into table dia_wormhole_cluster_pv partition(type='track');  //追加
load data local inpath '/jobcount/data' overwrite into table dia_wormhole_cluster_pv partition(type='track'); //覆盖

2. load hdfs 数据
load data inpath '/home/hdp_teu_dia/resultdata/zxl/input/2016/03/09' into table dia_wormhole_cluster_pv partition(type='track');
注：load data inpath是将数据move到表的存储位置下。分区表建议用add partition 的方式 添加数据，这样不会move数据

3. 从别的表中查询出相应的数据后导入到hive表
(追加数据)
insert into table hdp_teu_dia_defaultdb.dia_wormhole_cluster_pv
select pageType, count(pageType) as total,dia_date from hdp_teu_dia_defaultdb.dia_wormhole_usdt_infolist_car_pc
where  dia_date='20160308' group by pageType,dia_date;

（覆盖数据）
insert overwrite table hdp_teu_dia_defaultdb.dia_wormhole_cluster_pv
select pageType, count(pageType) as total,dia_date from hdp_teu_dia_defaultdb.dia_wormhole_usdt_infolist_car_pc
where  dia_date='20160308' group by pageType,dia_date;

 (覆盖分区表中分区的数据)
insert overwrite table dia_wormhole_cluster_pv partition(type='track')
select pageType, count(pageType) as total,dia_date from hdp_teu_dia_defaultdb.dia_wormhole_usdt_infolist_car_pc
where  dia_date='20160308' group by pageType,dia_date;

注：insert overwrite 覆盖表中的数据只会覆盖同名的文件，不会覆盖整个目录，有不重名的文件不会被覆盖
传统数据库的形式 insert into table values（字段1，字段2），这种形式hive是不支持的

4. 创建表的时候通过从别的表中查询出相应的记录并插入到所创建的表中
create table dia_wormhole_cluster_uv as select cluster_id,total,dia_date from dia_wormhole_cluster_pv;


=============================================>  修改表

1. 修改表名
ALTER TABLE table_name RENAME TO new_table_name

内部表不支持直接重命名，内部表若要重命名的步骤：1.将内部表转为外部表 2.外部表重命名 3.重命名后的外部表转为内部表

2. 添加分区
ALTER TABLE table_name ADD [IF NOT EXISTS] PARTITION partition_spec [LOCATION 'location'][, PARTITION partition_spec [LOCATION 'location'], ...];

例：alter table dia_wormhole_usdt_infolist_car_pc add partition (pageType='usdt_infodetail_car', dia_date='20160208')
location '/home/hdp_58_common/rawdata/wormhole/usdt_infodetail_car/track_pc/20160208';

添加分区时可以不写location ，如无location则此分区内的数据为空。

动态添加分区：
可以在select语句里面通过使用分区值来动态指明分区
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict;
insert into table test2  partition (age) select id, name, tel, age  from test1;

3. 修改分区
ALTER TABLE dia_wormhole_usdt_infolist_car_pc
PARTITION (dia_date='20160208') SET LOCATION "/home/hdp_58_common/rawdata/wormhole/usdt_infodetail_car/listshow_pc/20160208";

ALTER TABLE dia_wormhole_usdt_infolist_car_pc  PARTITION (dia_date='20160208') RENAME TO PARTITION (dt='dia_date='2016-02-08);

4. 删除分区
ALTER TABLE dia_wormhole_usdt_infolist_car_pc  DROP IF EXISTS PARTITION (pageType='usdt_infodetail_car', dia_date='20160208');

5. 添加列
ALTER TABLE dia_wormhole_cluster_pv ADD COLUMNS (type STRING);  //在所有存在的列后面，但是在分区列之前添加一列

6. 修改列
CREATE TABLE test_change (a int, b int, c int);
// will change column a's name to a1
ALTER TABLE test_change CHANGE a a1 INT;
// will change column a's name to a1, a's data type to string, and put it after column b. The new table's structure is: b int, a1 string, c int
ALTER TABLE test_change CHANGE a a1 STRING AFTER b;
// will change column b's name to b1, and put it as the first column. The new table's structure is: b1 int, a string, c int
ALTER TABLE test_change CHANGE b b1 INT FIRST;

7. 修改表/分区 localtion
ALTER TABLE table_name [PARTITION partition_spec] SET LOCATION "new location";
例：alter table tableName set location 'hdfs://hdp-58-cluster/home/...'



==================================> 显示hive表信息

show databases;
show tables;
describe dia_wormhole_usdt_infolist_car_pc; //查看表的结构信息
desc formatted dia_wormhole_usdt_infolist_car_pc; //查看表的结构信息，包含表的location，存储格式等信息
Show partitions dia_wormhole_usdt_infolist_car_pc; //查看表的分区
describe extended dia_wormhole_usdt_infolist_car_pc partiton (pageType='usdt_infodetail_car', dia_date='20160208')  //查看表分区的路径


==================================>  hive 视图

1. 创建视图
CREATE VIEW [IF NOT EXISTS] [db_name.]view_name [(column_name [COMMENT column_comment], ...) ]
[COMMENT view_comment]
[TBLPROPERTIES (property_name = property_value, ...)]
AS
SELECT ...;

举例:
CREATE VIEW onion_referrers(
url COMMENT 'URL of Referring page'
)COMMENT 'Referrers to The Onion website'
AS
SELECT DISTINCT referrer_url
FROM page_view
WHERE page_url='xxx';

2. 删除视图
DROP VIEW [IF EXISTS] [db_name.]view_name;



