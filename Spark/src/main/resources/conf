#spark参数


spark.sql.warehouse.dir
=>用于指定hive 中的 derby的路径

spark.sql.shuffle.partitions=500
=>设置shuffle时默认partition数目     很影响效率的参数，绝大部分sql都应该根据实际情况调整该参数

spark.default.parallelism=25
=>设置spark的默认并行度

spark.sql.adaptive.shuffle.targetPostShuffleInputSize=64*1024*1024
=>类似于 hive.exec.reducers.bytes.per.reducer 控制shuffle时单个task处理的数据量     	建议根据实际情况调整，会对效率有较大影响

spark.sql.files.maxPartitionBytes=128*1024*1024
=>partition读取的最大字节数       会影响效率，建议根据实际情况调整

spark.locality.wait=200ms
=>设置spark本地等待时间, 默认是3秒中等待, 如果超过3秒,低等级任务被调度执行;
注: PROCESS_LOCAL:进程本地化，NODE_LOCAL:节点本地化，NO_PREF,RACK_LOCAL:机架本地化,ANY:数据和task可能在集群中的任何地方;

spark.speculation=true
=>设置为TRUE表示开启Spark的推测执行
spark.speculation.multiplier=1.3
=>扫描到慢Task，执行时间是所有Task执行时间中值的1.4倍的时候启动另一个任务去并行运行这个Task











=======================================
spark.sql.warehouse.dir
=>用于指定hive 中的 derby的路径

spark.sql.shuffle.partitions=500
=>设置shuffle时默认partition数目     很影响效率的参数，绝大部分sql都应该根据实际情况调整该参数
spark.default.parallelism=25
=>设置spark的默认并行度


spark.sql.adaptive.shuffle.targetPostShuffleInputSize=64*1024*1024
=>类似于 hive.exec.reducers.bytes.per.reducer 控制shuffle时单个task处理的数据量     	建议根据实际情况调整，会对效率有较大影响
spark.sql.files.maxPartitionBytes=128*1024*1024
=>partition读取的最大字节数       会影响效率，建议根据实际情况调整


spark.locality.wait=200ms
=>设置spark本地等待时间, 默认是3秒中等待, 如果超过3秒,低等级任务被调度执行;
注: PROCESS_LOCAL:进程本地化，NODE_LOCAL:节点本地化，NO_PREF,RACK_LOCAL:机架本地化,ANY:数据和task可能在集群中的任何地方;
spark.speculation=true
=>设置为TRUE表示开启Spark的推测执行
spark.speculation.multiplier=1.3
=>扫描到慢Task，执行时间是所有Task执行时间中值的1.4倍的时候启动另一个任务去并行运行这个Task


spark.shuffle.consolidateFiles=true
=>开启shuffle map端输出文件合并的机制
spark.shuffle.file.buffer=64k
=>增加写磁盘缓存



spark.streaming.backpressure.enabled=true
=>sparkStreaming开启背压模式,用于应对数据的突然高峰



spark.sql.autoBroadcastJoinThreshold=10L*1024*1024
=>最大可被广播的表的大小    	效果类似于hive中的mapjoin ,注意基表无法被广播,内存充足时可结合实际表大小适当提高该值
spark.sql.broadcastTimeout=5*60
=>广播等待超时时间




spark.sql.parquet.mergeSchema=false
=>使用parquet时，是否合并schema          	如无需要不建议开启，消耗比较大
